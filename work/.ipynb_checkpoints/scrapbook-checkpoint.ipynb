{
 "metadata": {
  "name": "",
  "signature": "sha256:2e9124e48ef8dc4974ea5002c562b8399151cf98515a9a95fbaabb3ab91e4fb7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from nltk.corpus import stopwords\n",
      "import textmining"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from xml.dom import minidom"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xmldoc = minidom.parse('data/ap-test.xml')\n",
      "itemlist = xmldoc.getElementsByTagName('TEXT')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = {i : 0 for i in range(len(itemlist))}\n",
      "for j, s in enumerate(itemlist):\n",
      "    corpus[j] = s.childNodes[0].nodeValue"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tdm = textmining.TermDocumentMatrix()\n",
      "for i in range(len(corpus)):\n",
      "    tdm.add_doc(corpus[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tdm.write_csv('data/ap-test-tdm.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stop"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parseTextXML(filepath):\n",
      "    from xml.dom import minidom\n",
      "    from nltk.corpus import stopwords\n",
      "    stop = stopwords.words('english')\n",
      "    xmldoc = minidom.parse(filepath)\n",
      "    itemlist = xmldoc.getElementsByTagName('TEXT')\n",
      "    corpus = {i : 0 for i in range(len(itemlist))}\n",
      "    for j, s in enumerate(itemlist):\n",
      "        corpus_insert = s.childNodes[0].nodeValue.lower()\n",
      "        corpus_insert = [word for word in corpus_insert.split() if word not in stop]\n",
      "        corpus[j] = \" \".join(corpus_insert)\n",
      "    return corpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def writeTDM(corpus, outfile):\n",
      "        import textmining\n",
      "        tdm = textmining.TermDocumentMatrix()\n",
      "        for i in range(len(corpus)):\n",
      "                tdm.add_doc(corpus[i])\n",
      "        tdm.write_csv(outfile)\n",
      "\n",
      "writeTDM(parseTextXML(\"data/ap-test.xml\"), outfile='data/ap-test-tdm.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stop = stopwords.words('english')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "from numpy import genfromtxt\n",
      "from sklearn.preprocessing import normalize"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def loadAndProcessTDM(infile):\n",
      "    from numpy import genfromtxt\n",
      "    from sklearn.preprocessing import normalize\n",
      "    indata = genfromtxt(infile,\n",
      "                        delimiter=',',\n",
      "                        skip_header=1)\n",
      "    words = genfromtxt(infile,\n",
      "                       dtype=str,\n",
      "                       delimiter=',',\n",
      "                       skip_footer=len(indata))\n",
      "    indata = normalize(indata.astype(float))\n",
      "    return indata, words\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def matrixFactorization(inmatrix):\n",
      "        from sklearn.decomposition import PCA\n",
      "        from sklearn.decomposition import ProjectedGradientNMF\n",
      "        pca = PCA(n_components=inmatrix.shape[1])\n",
      "        pca.fit(inmatrix)\n",
      "        explained_variance = pca.explained_variance_ratio_.cumsum()\n",
      "        explained_variance = explained_variance[explained_variance <= .95]\n",
      "        p_comp = len(explained_variance)\n",
      "        model = ProjectedGradientNMF(n_components=p_comp,\n",
      "                                     init='nndsvd',\n",
      "                                     beta=1,\n",
      "                                     sparseness=None)\n",
      "        model.fit(inmatrix)\n",
      "        return model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dat, words = loadAndProcessTDM('data/ap-test-tdm.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dat.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 190,
       "text": [
        "(18, 422)"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blah = matrixFactorization(dat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blah.components_.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 107,
       "text": [
        "(15, 422)"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "df = pd.DataFrame(blah.components_)\n",
      "df.columns = words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pdb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def highMagnitudeFeatures(components, columns):\n",
      "        iter_list = []\n",
      "        for i in range(len(components)):\n",
      "                norm_component = components[i] / sum(components[i])\n",
      "                argsorted_components = numpy.argsort(norm_component)[::-1]\n",
      "                cumsum_components = numpy.cumsum(norm_component[argsorted_components]) > 0.95\n",
      "                if sum(numpy.logical_not(cumsum_components)) > 0:\n",
      "                        top_n_features = argsorted_components[0:numpy.where(cumsum_components)[0][0]]\n",
      "                else:\n",
      "                        top_n_features = numpy.array([argsorted_components[0]])\n",
      "                top_n_features = top_n_features.tolist()\n",
      "                iter_list.extend(top_n_features)\n",
      "        feature_counts = numpy.bincount(iter_list)\n",
      "        cutoff = numpy.floor(numpy.mean(feature_counts) + numpy.std(feature_counts))\n",
      "        drop_cols = columns[numpy.where(feature_counts > cutoff)]\n",
      "        return drop_cols"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "drop_cols = highMagnitudeFeatures(blah.components_, words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "idx = [int(numpy.where(words == drop_cols[i])[0]) for i in range(len(drop_cols))]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 168
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "idx_mask = numpy.ones((1, dat.shape[1]))\n",
      "idx_mask[:, idx] = 0\n",
      "idx_mask = idx_mask.astype(bool)\n",
      "\n",
      "idx_mask\n",
      "dat[:, idx_mask[0]].shape\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 220,
       "text": [
        "(18, 356)"
       ]
      }
     ],
     "prompt_number": 220
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words[idx_mask[0]].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 227,
       "text": [
        "(356,)"
       ]
      }
     ],
     "prompt_number": 227
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 187,
       "text": [
        "array([[ 0.07658396,  0.03829198,  0.        , ...,  0.        ,\n",
        "         0.        ,  0.03829198],\n",
        "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
        "         0.        ,  0.        ],\n",
        "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
        "         0.04079085,  0.        ],\n",
        "       ..., \n",
        "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
        "         0.        ,  0.        ],\n",
        "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
        "         0.04850713,  0.        ],\n",
        "       [ 0.04173919,  0.04173919,  0.        , ...,  0.        ,\n",
        "         0.16695677,  0.04173919]])"
       ]
      }
     ],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(blah.components_.shape[0]):\n",
      "    print i, words[blah.components_[i].argsort()[0:9]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 ['around' 'get' 'nearly' 'prime' 'miles' 'israeli' 'across' 'august' 'come']\n",
        "1 ['around' 'monday' 'except' 'rose' 'actress' 'without' 'oil' 'early'\n",
        " 'edwin']\n",
        "2 ['four' 'door' 'more' 'family' 'public' 'richard' 'past' 'gayle' 'none']\n",
        "3 ['four' 'town' 'known' 'door' 'israel' 'more' 'family' 'iraq' 'what']\n",
        "4 ['four' 'september' 'court' 'hour' 'none' 'town' 'known' 'israel' 'more']\n",
        "5 ['four' 'house' 'always' 'evening' 'might' 'september' 'court' 'states'\n",
        " 'none']\n",
        "6 ['around' 'think' 'first' 'labor' 'americans' 'vote' 'city' 'toward' 'll']\n",
        "7 ['four' 'major' 'american' 'success' 'members' 'issue' 'hard' 'house'\n",
        " 'always']\n",
        "8 ['four' 'a' 'court' 'states' 'hour' 'none' 'town' 'known' 'september']\n",
        "9 ['around' 'america' 'later' 'women' 'lieutenant' 'black' 'great' 'nearly'\n",
        " 'prime']\n",
        "10 ['four' 'recovered' 'believe' 'part' 'behind' 'least' 'automobile'\n",
        " 'slipped' 'major']\n",
        "11 ['women' 'comment' 'knew' 'career' 'shot' 'outside' 'going' 'black' 'group']\n",
        "12 ['four' 'moved' 'wife' 'caused' 'founded' 'tv' 'song' 'small' 'gayle']\n",
        "13 ['four' 'door' 'more' 'family' 'iraq' 'rate' 'gayle' 'town' 'small']\n",
        "14 ['around' 'truck' 'years' 'anything' 'police' 'half' 'run' 'popular'\n",
        " 'person']\n"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}